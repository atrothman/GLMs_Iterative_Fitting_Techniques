{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## load libraries ##\n",
    "####################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(123456789)\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Function for simulating Regression Model ##\n",
    "##############################################\n",
    "def simulate_df(n=1000, glm_type='logistic', seed=123456):\n",
    "    np.random.seed(seed)\n",
    "    df = pd.DataFrame()\n",
    "    ## specify variables L1 through L6\n",
    "    L1_split = 0.52\n",
    "    L2_split = 0.23\n",
    "    L3_split = 0.38\n",
    "    df['L0'] = n*[1]\n",
    "    df['L1'] = np.random.choice([0, 1], size=n, replace=True, p=[L1_split, (1-L1_split)])\n",
    "    df['L2'] = np.random.choice([0, 1], size=n, replace=True, p=[L2_split, (1-L2_split)])\n",
    "    df['L3'] = np.random.choice([0, 1], size=n, replace=True, p=[L3_split, (1-L3_split)])\n",
    "    df['L4'] = np.random.normal(0, 1, df.shape[0])\n",
    "    df['L5'] = np.random.normal(0, 0.75, df.shape[0])\n",
    "    df['L6'] = np.random.normal(0, 2, df.shape[0])\n",
    "    df['L4'] = df['L4'] / max(abs(df['L4']))\n",
    "    df['L5'] = df['L5'] / max(abs(df['L5']))\n",
    "    df['L6'] = df['L6'] / max(abs(df['L6']))\n",
    "    \n",
    "    ## define beta parameters\n",
    "    beta_0 = -0.3\n",
    "    beta_1 = -1.58\n",
    "    beta_2 = 1.75\n",
    "    beta_3 = 0.42\n",
    "    beta_4 = 1.32\n",
    "    beta_5 = -1.15\n",
    "    beta_6 = 1.12\n",
    "\n",
    "    if(glm_type=='logistic'):\n",
    "        df['Z'] = beta_0 + (beta_1*df['L1']) + (beta_2*df['L2']) + (beta_3*df['L3']) + (beta_4*df['L4']) + (beta_5*df['L5']) + (beta_6*df['L6'])\n",
    "        df['p'] = 1 / (1 + np.exp(-df['Z']))\n",
    "        df['Y'] = np.random.binomial(1, df['p'])\n",
    "        model = smf.glm('Y ~ L1 + L2 + L3 + L4 + L5 + L6', data=df, family=sm.families.Binomial()).fit()\n",
    "    \n",
    "    if(glm_type=='poisson'):\n",
    "        df['Z'] = beta_0 + (beta_1*df['L1']) + (beta_2*df['L2']) + (beta_3*df['L3']) + (beta_4*df['L4']) + (beta_5*df['L5']) + (beta_6*df['L6'])\n",
    "        df['p'] = np.exp(df['Z'])\n",
    "        df['Y'] = None\n",
    "        for i in range(0, df.shape[0]):\n",
    "            df.loc[i, 'Y'] = np.random.poisson(df.loc[i, 'p'], 1)\n",
    "        df['Y'] = df['Y'].astype(float)\n",
    "        model = smf.glm('Y ~ L1 + L2 + L3 + L4 + L5 + L6', data=df, family=sm.families.Poisson()).fit()\n",
    "    \n",
    "    if(glm_type=='probit'):\n",
    "        df['Z'] = beta_0 + (beta_1*df['L1']) + (beta_2*df['L2']) + (beta_3*df['L3']) + (beta_4*df['L4']) + (beta_5*df['L5']) + (beta_6*df['L6'])\n",
    "        df['p'] = norm.cdf(df['Z'])\n",
    "        df['Y'] = np.random.binomial(1, df['p'])\n",
    "        model = statsmodels.discrete.discrete_model.Probit(df['Y'], df[['L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']]).fit()\n",
    "    \n",
    "    return(df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Activation Functions ##\n",
    "##########################\n",
    "def sigmoid_activation(Z):\n",
    "    p = 1 / (1 + np.exp(-Z))\n",
    "    return(p)\n",
    "\n",
    "def exponential_activation(Z):\n",
    "    p = np.exp(Z)\n",
    "    return(p)\n",
    "    \n",
    "def probit_activation(Z):\n",
    "    p = norm.cdf(Z)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "## Function for Newton-Raphson and Fisher Scoring for Canonical GLMs ##\n",
    "#######################################################################\n",
    "def NewtonRaphson_FisherScoring_Canonical(df, glm_type='logistic', seed=123456):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    ## specify number of observations and number of features (including intercept)\n",
    "    n = df.shape[0]\n",
    "    m = 7\n",
    "    if(glm_type=='logistic'):\n",
    "        k = 10\n",
    "    if(glm_type=='poisson'):\n",
    "        k = 100\n",
    "        \n",
    "    ## specify the Target Y\n",
    "    Y = np.array(df['Y']).reshape((n,1))\n",
    "    ## specify design matrix X        \n",
    "    X = np.array(df[['L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']])\n",
    "    ## initialize Beta vector:\n",
    "    Beta = np.random.normal(0, 0.5, m).reshape((m, 1))\n",
    "        \n",
    "    ## calculate the initial cost J\n",
    "    if(glm_type=='logistic'):\n",
    "        b_theta = np.log(1+np.exp(np.dot(X, Beta)))\n",
    "    if(glm_type=='poisson'):\n",
    "        b_theta = np.exp(np.dot(X, Beta))\n",
    "    J = np.sum(b_theta - (np.dot(X, Beta) * Y))\n",
    "        \n",
    "    ## dataframe to hold algo results\n",
    "    df_algo_results = pd.DataFrame()\n",
    "    df_algo_results['k'] = list(range(0, k+1))\n",
    "    df_algo_results['J'] = None\n",
    "    df_algo_results.loc[0, 'J'] = J\n",
    "    del b_theta, J\n",
    "        \n",
    "    for i in range(0, k):    \n",
    "        ## get linear predictor Z\n",
    "        Z = np.dot(X, Beta)\n",
    "        ## get prediction p\n",
    "        if(glm_type=='logistic'):\n",
    "            p = sigmoid_activation(Z)\n",
    "        if(glm_type=='poisson'):\n",
    "            p = exponential_activation(Z)\n",
    "        ## get variance matrix V\n",
    "        V = np.diag(((p-Y)**2).squeeze(axis=1))\n",
    "\n",
    "        ## calculate the Hessian\n",
    "        Hessian = np.linalg.solve(np.dot(X.T, V).dot(X), np.eye(m))\n",
    "        \n",
    "        ## calculate dJ_Beta\n",
    "        dJ_Beta = np.dot(X.T, (p-Y))\n",
    "        \n",
    "        ## get the updated Beta\n",
    "        Beta = Beta - np.dot(Hessian, dJ_Beta)\n",
    "            \n",
    "        ## record cost function\n",
    "        if(glm_type=='logistic'):\n",
    "            b_theta = np.log(1+np.exp(np.dot(X, Beta)))\n",
    "        if(glm_type=='poisson'):\n",
    "            b_theta = np.exp(np.dot(X, Beta))\n",
    "        J = np.sum(b_theta - (np.dot(X, Beta) * Y))\n",
    "        df_algo_results.loc[i+1, 'J'] = J\n",
    "            \n",
    "        del J, b_theta, Z, p, V, Hessian, dJ_Beta\n",
    "    \n",
    "    return(Beta, df_algo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Function for IRLS for Canonical GLMs ##\n",
    "##########################################\n",
    "def IRLS_Canonical(df, glm_type='logistic', seed=123456):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    ## specify number of observations and number of features (including intercept)\n",
    "    n = df.shape[0]\n",
    "    m = 7\n",
    "    if(glm_type=='logistic'):\n",
    "        k = 10\n",
    "    if(glm_type=='poisson'):\n",
    "        k = 100\n",
    "        \n",
    "    ## specify the Target Y\n",
    "    Y = np.array(df['Y']).reshape((n,1))\n",
    "    ## specify design matrix X        \n",
    "    X = np.array(df[['L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']])\n",
    "    ## initialize Beta vector:\n",
    "    Beta = np.random.normal(0, 0.5, m).reshape((m, 1))\n",
    "        \n",
    "    ## calculate the initial cost J\n",
    "    if(glm_type=='logistic'):\n",
    "        b_theta = np.log(1+np.exp(np.dot(X, Beta)))\n",
    "    if(glm_type=='poisson'):\n",
    "        b_theta = np.exp(np.dot(X, Beta))\n",
    "    J = np.sum(b_theta - (np.dot(X, Beta) * Y))\n",
    "        \n",
    "    ## dataframe to hold algo results\n",
    "    df_algo_results = pd.DataFrame()\n",
    "    df_algo_results['k'] = list(range(0, k+1))\n",
    "    df_algo_results['J'] = None\n",
    "    df_algo_results.loc[0, 'J'] = J\n",
    "    del b_theta, J\n",
    "        \n",
    "    for i in range(0, k):    \n",
    "        ## get linear predictor Z\n",
    "        Z = np.dot(X, Beta)\n",
    "        ## get prediction p\n",
    "        if(glm_type=='logistic'):\n",
    "            p = sigmoid_activation(Z)\n",
    "        if(glm_type=='poisson'):\n",
    "            p = exponential_activation(Z)\n",
    "        ## get variance matrix V\n",
    "        V = np.diag(((p-Y)**2).squeeze(axis=1))\n",
    "        \n",
    "        ## get matrix W_inv and Y_til\n",
    "        W_inv = V\n",
    "        Y_til = 1 / (p-Y)\n",
    "            \n",
    "        ## calculate WLS estimator\n",
    "        WLS = np.linalg.solve(np.dot(X.T, W_inv).dot(X), np.eye(m)).dot(X.T).dot(W_inv).dot(Y_til)            \n",
    "            \n",
    "        ## get the updated Beta\n",
    "        Beta = Beta - WLS\n",
    "            \n",
    "        ## record cost function\n",
    "        if(glm_type=='logistic'):\n",
    "            b_theta = np.log(1+np.exp(np.dot(X, Beta)))\n",
    "        if(glm_type=='poisson'):\n",
    "            b_theta = np.exp(np.dot(X, Beta))\n",
    "        J = np.sum(b_theta - (np.dot(X, Beta) * Y))\n",
    "        df_algo_results.loc[i+1, 'J'] = J\n",
    "            \n",
    "        del J, b_theta, Z, p, V, W_inv, Y_til, WLS\n",
    "    \n",
    "    return(Beta, df_algo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Function for Newton-Raphson for Non-Canonical GLMs ##\n",
    "########################################################\n",
    "def NewtonRaphson_NonCanonical(df, seed=123456):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    ## specify number of observations and number of features (including intercept)\n",
    "    n = df.shape[0]\n",
    "    m = 7\n",
    "    k = 20\n",
    "        \n",
    "    ## specify the Target Y\n",
    "    Y = np.array(df['Y']).reshape((n,1))\n",
    "    ## specify design matrix X        \n",
    "    X = np.array(df[['L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']])\n",
    "    ## initialize Beta vector:\n",
    "    Beta = np.random.normal(0, 0.5, m).reshape((m, 1))\n",
    "        \n",
    "    ## calculate the initial cost J\n",
    "    T_y = Y\n",
    "    Eta = np.dot(X, Beta)\n",
    "    h_eta = probit_activation(Eta)\n",
    "    xi = h_eta\n",
    "    r_xi = np.log(xi / (1-xi)) \n",
    "    b_xi = -np.log(1 - xi)\n",
    "    J = np.sum(b_xi - (T_y * r_xi))\n",
    "    \n",
    "    ## dataframe to hold algo results\n",
    "    df_algo_results = pd.DataFrame()\n",
    "    df_algo_results['k'] = list(range(0, k+1))\n",
    "    df_algo_results['J'] = None\n",
    "    df_algo_results.loc[0, 'J'] = J\n",
    "    del Eta, h_eta, xi, b_xi, r_xi, J\n",
    "               \n",
    "    for i in range(0, k):    \n",
    "        ## get linear predictor Eta\n",
    "        Eta = np.dot(X, Beta)\n",
    "        \n",
    "        ## get activation function h_eta\n",
    "        h_eta = probit_activation(Eta)\n",
    "        ## get first derivative of h_eta with respect to eta\n",
    "        dh_deta = norm.pdf(Eta)\n",
    "        \n",
    "        ## get prediction xi\n",
    "        xi = h_eta\n",
    "        \n",
    "        ## get function r_xi\n",
    "        r_xi = np.log(xi / (1-xi)) \n",
    "        ## get first derivative of r_xi with respect to xi\n",
    "        dr_dxi = 1 / (xi-(xi**2))\n",
    "        ## get second derivative of r_xi with respect to xi\n",
    "        d2r_d2xi = ((2*xi)-1) / ((xi-(xi**2))**2)\n",
    "        \n",
    "        ## get function b_xi\n",
    "        b_xi = -np.log(1 - xi)\n",
    "        ## get first derivative of b_xi with respect to xi\n",
    "        db_dxi = 1 / (1-xi)\n",
    "        ## get second derivative of b_xi with respect to xi\n",
    "        d2b_d2xi = (2-xi) / ((1-xi)**2)\n",
    "        \n",
    "        ## calculate the Hessian\n",
    "        Hessian = np.linalg.solve(np.dot(X.T, np.diag(((d2b_d2xi - (T_y*d2r_d2xi))*(dh_deta**2)).squeeze(axis=1))).dot(X), np.eye(m))                                          \n",
    "        \n",
    "        ## calculate dJ_Beta\n",
    "        dJ_Beta = np.dot(X.T, ((db_dxi - (T_y*dr_dxi)) * dh_deta))\n",
    "        \n",
    "        ## get the updated Beta\n",
    "        Beta = Beta - np.dot(Hessian, dJ_Beta)\n",
    "        del Eta, h_eta, dh_deta, xi, r_xi, dr_dxi, d2r_d2xi, b_xi, db_dxi, d2b_d2xi, Hessian, dJ_Beta\n",
    "        \n",
    "        ## calculate the updated cost J\n",
    "        Eta = np.dot(X, Beta)\n",
    "        h_eta = probit_activation(Eta)\n",
    "        xi = h_eta\n",
    "        r_xi = np.log(xi / (1-xi)) \n",
    "        b_xi = -np.log(1 - xi)\n",
    "        J = np.sum(b_xi - (T_y * r_xi))\n",
    "        df_algo_results.loc[i+1, 'J'] = J\n",
    "        del Eta, h_eta, xi, b_xi, r_xi, J\n",
    "    \n",
    "    return(Beta, df_algo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Function for Fisher Scoring for Non-Canonical GLMs ##\n",
    "########################################################\n",
    "def FisherScoring_NonCanonical(df, seed=123456):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    ## specify number of observations and number of features (including intercept)\n",
    "    n = df.shape[0]\n",
    "    m = 7\n",
    "    k = 10\n",
    "        \n",
    "    ## specify the Target Y\n",
    "    Y = np.array(df['Y']).reshape((n,1))\n",
    "    ## specify design matrix X        \n",
    "    X = np.array(df[['L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']])\n",
    "    ## initialize Beta vector:\n",
    "    Beta = np.random.normal(0, 0.5, m).reshape((m, 1))\n",
    "        \n",
    "    ## calculate the initial cost J\n",
    "    T_y = Y\n",
    "    Eta = np.dot(X, Beta)\n",
    "    h_eta = probit_activation(Eta)\n",
    "    xi = h_eta\n",
    "    r_xi = np.log(xi / (1-xi)) \n",
    "    b_xi = -np.log(1 - xi)\n",
    "    J = np.sum(b_xi - (T_y * r_xi))    \n",
    "    \n",
    "    ## dataframe to hold algo results\n",
    "    df_algo_results = pd.DataFrame()\n",
    "    df_algo_results['k'] = list(range(0, k+1))\n",
    "    df_algo_results['J'] = None\n",
    "    df_algo_results.loc[0, 'J'] = J\n",
    "    del Eta, h_eta, xi, b_xi, r_xi, J\n",
    "               \n",
    "    for i in range(0, k):    \n",
    "        ## get linear predictor Eta\n",
    "        Eta = np.dot(X, Beta)\n",
    "        \n",
    "        ## get activation function h_eta\n",
    "        h_eta = probit_activation(Eta)\n",
    "        ## get first derivative of h_eta with respect to eta\n",
    "        dh_deta = norm.pdf(Eta)\n",
    "        \n",
    "        ## get prediction xi\n",
    "        xi = h_eta\n",
    "        \n",
    "        ## get function r_xi\n",
    "        r_xi = np.log(xi / (1-xi)) \n",
    "        ## get first derivative of r_xi with respect to xi\n",
    "        dr_dxi = 1 / (xi-(xi**2))\n",
    "        ## get second derivative of r_xi with respect to xi\n",
    "        d2r_d2xi = ((2*xi)-1) / ((xi-(xi**2))**2)\n",
    "        \n",
    "        ## get function b_xi\n",
    "        b_xi = -np.log(1 - xi)\n",
    "        ## get first derivative of b_xi with respect to xi\n",
    "        db_dxi = 1 / (1-xi)\n",
    "        ## get second derivative of b_xi with respect to xi\n",
    "        d2b_d2xi = (2-xi) / ((1-xi)**2)\n",
    "        \n",
    "        ## calculate the Fisher Information\n",
    "        FisherInformation = np.linalg.solve(np.dot(X.T, np.diag(((dr_dxi**2)*(dh_deta**2)*((xi-T_y)**2)).squeeze(axis=1))).dot(X), np.eye(m)) \n",
    "\n",
    "        ## calculate dJ_Beta\n",
    "        dJ_Beta = np.dot(X.T, ((db_dxi - (T_y*dr_dxi)) * dh_deta))\n",
    "        \n",
    "        ## get the updated Beta\n",
    "        Beta = Beta - np.dot(FisherInformation, dJ_Beta)\n",
    "        del Eta, h_eta, dh_deta, xi, r_xi, dr_dxi, d2r_d2xi, b_xi, db_dxi, d2b_d2xi, FisherInformation, dJ_Beta\n",
    "        \n",
    "        ## calculate the updated cost J\n",
    "        Eta = np.dot(X, Beta)\n",
    "        h_eta = probit_activation(Eta)\n",
    "        xi = h_eta\n",
    "        r_xi = np.log(xi / (1-xi)) \n",
    "        b_xi = -np.log(1 - xi)\n",
    "        J = np.sum(b_xi - (T_y * r_xi))\n",
    "        df_algo_results.loc[i+1, 'J'] = J\n",
    "        del Eta, h_eta, xi, b_xi, r_xi, J\n",
    "    \n",
    "    return(Beta, df_algo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Function for IRLS for Non-Canonical GLMs ##\n",
    "##############################################\n",
    "def IRLS_NonCanonical(df, seed=123456):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    ## specify number of observations and number of features (including intercept)\n",
    "    n = df.shape[0]\n",
    "    m = 7\n",
    "    k = 10\n",
    "        \n",
    "    ## specify the Target Y\n",
    "    Y = np.array(df['Y']).reshape((n,1))\n",
    "    ## specify design matrix X        \n",
    "    X = np.array(df[['L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6']])\n",
    "    ## initialize Beta vector:\n",
    "    Beta = np.random.normal(0, 0.5, m).reshape((m, 1))\n",
    "        \n",
    "    ## calculate the initial cost J\n",
    "    T_y = Y\n",
    "    Eta = np.dot(X, Beta)\n",
    "    h_eta = probit_activation(Eta)\n",
    "    xi = h_eta\n",
    "    r_xi = np.log(xi / (1-xi)) \n",
    "    b_xi = -np.log(1 - xi)\n",
    "    J = np.sum(b_xi - (T_y * r_xi))    \n",
    "    \n",
    "    ## dataframe to hold algo results\n",
    "    df_algo_results = pd.DataFrame()\n",
    "    df_algo_results['k'] = list(range(0, k+1))\n",
    "    df_algo_results['J'] = None\n",
    "    df_algo_results.loc[0, 'J'] = J\n",
    "    del Eta, h_eta, xi, b_xi, r_xi, J\n",
    "               \n",
    "    for i in range(0, k):    \n",
    "        ## get linear predictor Eta\n",
    "        Eta = np.dot(X, Beta)\n",
    "        \n",
    "        ## get activation function h_eta\n",
    "        h_eta = probit_activation(Eta)\n",
    "        ## get first derivative of h_eta with respect to eta\n",
    "        dh_deta = norm.pdf(Eta)\n",
    "        \n",
    "        ## get prediction xi\n",
    "        xi = h_eta\n",
    "        \n",
    "        ## get function r_xi\n",
    "        r_xi = np.log(xi / (1-xi)) \n",
    "        ## get first derivative of r_xi with respect to xi\n",
    "        dr_dxi = 1 / (xi-(xi**2))\n",
    "        ## get second derivative of r_xi with respect to xi\n",
    "        d2r_d2xi = ((2*xi)-1) / ((xi-(xi**2))**2)\n",
    "        \n",
    "        ## get function b_xi\n",
    "        b_xi = -np.log(1 - xi)\n",
    "        ## get first derivative of b_xi with respect to xi\n",
    "        db_dxi = 1 / (1-xi)\n",
    "        ## get second derivative of b_xi with respect to xi\n",
    "        d2b_d2xi = (2-xi) / ((1-xi)**2)\n",
    "        \n",
    "        ## get matrix W_inv and Y_til\n",
    "        W_inv = np.diag(((dr_dxi**2)*(dh_deta**2)*((xi-T_y)**2)).squeeze(axis=1))\n",
    "        Y_til = 1 / (dr_dxi * dh_deta * (xi-T_y))\n",
    "        \n",
    "        ## calculate WLS estimator\n",
    "        WLS = np.linalg.solve(np.dot(X.T, W_inv).dot(X), np.eye(m)).dot(X.T).dot(W_inv).dot(Y_til)  \n",
    "                \n",
    "        ## get the updated Beta\n",
    "        Beta = Beta - WLS\n",
    "        del Eta, h_eta, dh_deta, xi, r_xi, dr_dxi, d2r_d2xi, b_xi, db_dxi, d2b_d2xi, WLS\n",
    "        \n",
    "        ## calculate the updated cost J\n",
    "        Eta = np.dot(X, Beta)\n",
    "        h_eta = probit_activation(Eta)\n",
    "        xi = h_eta\n",
    "        r_xi = np.log(xi / (1-xi)) \n",
    "        b_xi = -np.log(1 - xi)\n",
    "        J = np.sum(b_xi - (T_y * r_xi))\n",
    "        df_algo_results.loc[i+1, 'J'] = J\n",
    "        del Eta, h_eta, xi, b_xi, r_xi, J\n",
    "    \n",
    "    return(Beta, df_algo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      993\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -540.88\n",
      "Date:                Mon, 03 May 2021   Deviance:                       1081.8\n",
      "Time:                        16:06:16   Pearson chi2:                     970.\n",
      "No. Iterations:                     4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1731      0.186     -0.932      0.352      -0.537       0.191\n",
      "L1            -1.5365      0.157     -9.808      0.000      -1.844      -1.229\n",
      "L2             1.6923      0.183      9.272      0.000       1.335       2.050\n",
      "L3             0.3497      0.152      2.305      0.021       0.052       0.647\n",
      "L4             1.3041      0.247      5.282      0.000       0.820       1.788\n",
      "L5            -1.0942      0.244     -4.483      0.000      -1.573      -0.616\n",
      "L6             1.1910      0.250      4.758      0.000       0.700       1.682\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Logistic Regression ##\n",
    "#########################\n",
    "df_logistic, model_logistic = simulate_df(n=1000, glm_type='logistic')\n",
    "print(model_logistic.summary())\n",
    "## Newton Raphson / Fisher Scoring\n",
    "Beta_Logistic_NR, df_Logistic_cost_NR = NewtonRaphson_FisherScoring_Canonical(df=df_logistic, glm_type='logistic', seed=123456)\n",
    "## IRLS\n",
    "Beta_Logistic_IRLS, df_Logistic_cost_IRLS = IRLS_Canonical(df=df_logistic, glm_type='logistic', seed=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17312538]\n",
      " [-1.53654037]\n",
      " [ 1.69232727]\n",
      " [ 0.34965883]\n",
      " [ 1.30410149]\n",
      " [-1.09423892]\n",
      " [ 1.1910266 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Logistic_NR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17312538]\n",
      " [-1.53654037]\n",
      " [ 1.69232727]\n",
      " [ 0.34965883]\n",
      " [ 1.30410149]\n",
      " [-1.09423892]\n",
      " [ 1.1910266 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Logistic_IRLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      993\n",
      "Model Family:                 Poisson   Df Model:                            6\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1605.6\n",
      "Date:                Mon, 03 May 2021   Deviance:                       1026.7\n",
      "Time:                        16:06:46   Pearson chi2:                     989.\n",
      "No. Iterations:                     6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.4635      0.092     -5.065      0.000      -0.643      -0.284\n",
      "L1            -1.5961      0.045    -35.238      0.000      -1.685      -1.507\n",
      "L2             1.9576      0.090     21.868      0.000       1.782       2.133\n",
      "L3             0.4151      0.038     11.050      0.000       0.341       0.489\n",
      "L4             1.3107      0.059     22.051      0.000       1.194       1.427\n",
      "L5            -1.1978      0.054    -22.339      0.000      -1.303      -1.093\n",
      "L6             1.0616      0.054     19.580      0.000       0.955       1.168\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "## Poisson Regression ##\n",
    "########################\n",
    "df_poisson, model_poisson = simulate_df(n=1000, glm_type='poisson')\n",
    "print(model_poisson.summary())\n",
    "## Newton Raphson / Fisher Scoring\n",
    "Beta_Poisson_NR, df_Poisson_cost_NR = NewtonRaphson_FisherScoring_Canonical(df=df_poisson, glm_type='poisson', seed=123456)\n",
    "## IRLS\n",
    "Beta_Poisson_IRLS, df_Poisson_cost_IRLS = IRLS_Canonical(df=df_poisson, glm_type='poisson', seed=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46354375]\n",
      " [-1.5960801 ]\n",
      " [ 1.95764143]\n",
      " [ 0.41513364]\n",
      " [ 1.31072289]\n",
      " [-1.19784871]\n",
      " [ 1.06158341]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Poisson_NR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46354375]\n",
      " [-1.5960801 ]\n",
      " [ 1.95764143]\n",
      " [ 0.41513364]\n",
      " [ 1.31072289]\n",
      " [-1.19784871]\n",
      " [ 1.06158341]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Poisson_IRLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.400630\n",
      "         Iterations 7\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                 1000\n",
      "Model:                         Probit   Df Residuals:                      993\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Mon, 03 May 2021   Pseudo R-squ.:                  0.3910\n",
      "Time:                        16:07:22   Log-Likelihood:                -400.63\n",
      "converged:                       True   LL-Null:                       -657.88\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.304e-108\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "L0            -0.2544      0.126     -2.024      0.043      -0.501      -0.008\n",
      "L1            -1.6821      0.120    -14.035      0.000      -1.917      -1.447\n",
      "L2             1.7898      0.137     13.085      0.000       1.522       2.058\n",
      "L3             0.4204      0.104      4.031      0.000       0.216       0.625\n",
      "L4             1.2129      0.170      7.136      0.000       0.880       1.546\n",
      "L5            -1.1627      0.171     -6.788      0.000      -1.498      -0.827\n",
      "L6             1.1596      0.177      6.544      0.000       0.812       1.507\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "## Probit Regression ##\n",
    "#######################\n",
    "df_probit, model_probit = simulate_df(n=1000, glm_type='probit')\n",
    "print(model_probit.summary())\n",
    "## Newton Raphson\n",
    "Beta_Probit_NR, df_Probit_cost_NR = NewtonRaphson_NonCanonical(df=df_probit, seed=123456)\n",
    "## Fisher Scoring\n",
    "Beta_Probit_FS, df_Probit_cost_FS = FisherScoring_NonCanonical(df=df_probit, seed=123456)\n",
    "## IRLS\n",
    "Beta_Probit_IRLS, df_Probit_cost_IRLS = IRLS_NonCanonical(df=df_probit, seed=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25437885]\n",
      " [-1.68207182]\n",
      " [ 1.78983894]\n",
      " [ 0.42038955]\n",
      " [ 1.21294796]\n",
      " [-1.16274506]\n",
      " [ 1.15957839]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Probit_NR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2543798 ]\n",
      " [-1.68207257]\n",
      " [ 1.78984032]\n",
      " [ 0.42038961]\n",
      " [ 1.2129496 ]\n",
      " [-1.16274281]\n",
      " [ 1.15957877]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Probit_FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2543798 ]\n",
      " [-1.68207257]\n",
      " [ 1.78984032]\n",
      " [ 0.42038961]\n",
      " [ 1.2129496 ]\n",
      " [-1.16274281]\n",
      " [ 1.15957877]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta_Probit_IRLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ai/atrothman/glms-newton-raphson-fisher-scoring-irls-simulations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/atrothman/glms-newton-raphson-fisher-scoring-irls-simulations'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
